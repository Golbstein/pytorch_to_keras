{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Pytorch weights to Keras model\n",
    "Jenia Golbstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from keras.layers import Conv2D, Input, Dense, MaxPool2D, Flatten, Lambda, BatchNormalization\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy PyTorch model\n",
    "\n",
    "* Model with convolution, bachnormalization and fully connected layer\n",
    "* For input @ size (28x28x1) - MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchModel(\n",
       "  (conv1): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=338, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PytorchModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PytorchModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=2)\n",
    "        self.fc1 = nn.Linear(13*13*2, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(F.relu(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 13*13*2)\n",
    "        x = self.fc1(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "# Load dummpy pytorch model to cpu on evaluation mode\n",
    "p_model = PytorchModel()\n",
    "p_model.cpu()\n",
    "p_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy Keras model\n",
    "\n",
    "* #### Similar architecture as the Pytorch model\n",
    "* #### tensorflow backend with image_data_format=\"channels_last\"\n",
    "\n",
    "\n",
    "* Pytorch input order is (B, C, H, W). \n",
    "* Keras input order (channels_last) is (B, H, W, C)\n",
    "\n",
    "\n",
    "Therefore, when you do flattening of the activations (\"view\" in pytorch) you have to reshape you input to be like the input in your pytorch model so the pre-trained pytorch weights will be relevant.\n",
    "\n",
    "Also, I don't know why and if anyone can explain me this - it's necessary to do this trick before the BatchNormalization layer in keras and reshape back afterwards to (BHWC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "# Make sure it's \"channels_last\"\n",
    "print(K.image_data_format()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build keras model on cpu\n",
    "with tf.device('/cpu:0'):\n",
    "    inp = Input((28,28,1))\n",
    "    x = Conv2D(2,3,activation='relu', name='conv1')(inp)\n",
    "    \n",
    "    # Reshaping to (BCHW)\n",
    "    x = Lambda(lambda x: K.permute_dimensions(x, (0, 3, 1, 2)))(x)\n",
    "    x = BatchNormalization(axis = 1, name='bn1')(x)\n",
    "    \n",
    "    # Reshaping back to (BHWC)\n",
    "    x = Lambda(lambda x: K.permute_dimensions(x, (0, 2, 3, 1)))(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    # Reshaping to (BCHW)\n",
    "    x = Lambda(lambda x: K.permute_dimensions(x, (0, 3, 1, 2)))(x)\n",
    "    x = Flatten()(x)\n",
    "    out = Dense(10, activation='softmax',name='fc1')(x)\n",
    "    k_model = Model(inp, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch to Keras weights conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytoch weights to keras\n",
    "\n",
    "trained_weights = p_model.state_dict()\n",
    "pytorch_layers = [] # get ptroch layers names and suffixes\n",
    "for x, l in zip(trained_weights, k_model.layers):\n",
    "    pytorch_layers.append(x[:x.find('.')])\n",
    "\n",
    "unique_layers = np.unique(pytorch_layers)\n",
    "\n",
    "for layer in unique_layers:\n",
    "    weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "    biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "    if 'bn' in layer:\n",
    "        running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "        running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "        W = [weights, biases, running_mean, running_var]\n",
    "    elif 'fc' in layer:\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        W = [weights.T, biases]\n",
    "    else:\n",
    "        W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "    k_model.get_layer(layer).set_weights(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the output of the 2 models on randomly uniformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max difference: 4.455447e-06 \n",
      "sum of difffernces: -4.7683716e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "keras_input = np.random.random((batch_size, 28, 28, 1)).astype('float32')\n",
    "pytorch_input = torch.from_numpy(keras_input.transpose(0,-1,1,2))\n",
    "\n",
    "p_out = p_model(pytorch_input.cpu())\n",
    "k_out = k_model.predict(keras_input)\n",
    "\n",
    "y = torch.from_numpy(k_out) - p_out\n",
    "y = y.detach().numpy().flatten()\n",
    "plt.hist(y);\n",
    "print('max difference:', y.max(), '\\nsum of difffernces:', y.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
